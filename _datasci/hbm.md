---
title: "Here Be Monsters: Deepfaking Nixon"
collection: datasci
permalink: /datasci/hbm
excerpt: 'On this episode of Here Be Monsters, Francesca and Halsey tell producer Jeff Emtman that deepfakes aren’t going to rupture society. Also on this episode, Ahnjili explains how computers learn to speak, and we listen to some audio examples of how computer voices can fail, using examples from the paper Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis.'
date: 2019-Jan-02
---

From Jeff who organized the project:

On this episode of Here Be Monsters, Francesca and Halsey tell producer Jeff Emtman that deepfakes aren’t going to rupture society.  We’ve dealt with this before, whether it’s darkroom manipulations or photoshop, societies eventually learn how to detect deception.  But the adjustment period can be rough, and they hope that In Event of Moon Disaster will help educate media consumers on the danger of taking media at face value, regardless of whether it’s deepfakes or just old-fashioned photo mis-captioning.

Also on this episode, Ahnjili explains how computers learn to speak, and we listen to some audio examples of how computer voices can fail, using examples from the paper Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis.  Also heard: a presidential  parody deepfake from user Stable Voices on Youtube. 

More on: https://www.hbmpodcast.com/podcast/hbm125-deepfaking-nixon
